{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab237034-560b-4ad3-a40d-555992e9bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import glob\n",
    "\n",
    "def parse_job_offers(input_folder, output_csv):\n",
    "    \"\"\"\n",
    "    Parses job listings from a folder with HTML files and writes the data to a CSV file.\n",
    "\n",
    "    Arguments:\n",
    "    input_folder (str): Path to the folder with raw data.\n",
    "    output_csv (str): Path to the output CSV file.\n",
    "    \"\"\"\n",
    "    html_files = glob.glob(f\"{input_folder}*.html\")\n",
    "    data = []\n",
    "    for html_file in html_files:\n",
    "    \n",
    "        # Load and parse HTML\n",
    "        with open(html_file, 'r', encoding='utf-8') as f:\n",
    "            soup = BeautifulSoup(f, 'html.parser')\n",
    "\n",
    "        \n",
    "        # Search name information\n",
    "        job = soup.find('input', {'name': 'kw'}).get('value')\n",
    "\n",
    "        # Find Jobs Sections\n",
    "        job_offers = soup.find_all('div', {'data-test': 'positioned-offer'})\n",
    "        for offer in job_offers:\n",
    "            # Extract data: job title\n",
    "            title = offer.find('h2', {'data-test': 'offer-title'}).text.strip()\n",
    "        \n",
    "            # Company name\n",
    "            company = offer.find('h3', {'data-test': 'text-company-name'}).text.strip()\n",
    "        \n",
    "            # Location\n",
    "            location = offer.find('h4', {'data-test': 'text-region'}).text.strip()\n",
    "\n",
    "            # Salary\n",
    "            salary_find = offer.find('span', {'data-test': 'offer-salary'}) \n",
    "            if salary_find:\n",
    "                salary = salary_find.text.strip()\n",
    "            else:\n",
    "                salary = \"\"\n",
    "        \n",
    "            # technologies\n",
    "            technologies = [tech.text.strip() for tech in offer.find_all('span', {'data-test': 'technologies-item'})] \n",
    "        \n",
    "            # Adding to data\n",
    "            data.append([title, company, ', '.join(technologies), job, location, salary])  \n",
    "\n",
    "    # Save to CSV\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Title', 'Company', 'Technologies', 'Job', 'Location', 'Salary'])\n",
    "        writer.writerows(data)\n",
    "\n",
    "# Example of use:\n",
    "parse_job_offers(r\"../data/raw/\", r\"..\\data\\interim\\job_offers.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "433ee9e3-3284-4905-8eae-ecc84ed2050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to HTML file\n",
    "file_path = r\"..\\data\\raw\\data analyst_1.html\"\n",
    "\n",
    "# Loading HTML file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "soup1 = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "technologies = [tech.text.strip() for tech in soup1.find_all('span', {'data-test': 'technologies-item'})]\n",
    "\n",
    "jobs = [soup1.text.strip() for soup1 in soup1.find_all('div', {'data-test': 'positioned-offer'})]\n",
    "\n",
    "salary = soup1.find('span', {'data-test': 'offer-salary'}).text.strip().replace('\\xa0', '')\n",
    "\n",
    "job = soup1.find('input', {'name': 'kw'})\n",
    "job_value = job.get('value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560efa91-2ffb-4137-9940-2f667b0645c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
